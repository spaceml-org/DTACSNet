{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Index","text":""},{"location":"index.html#dtacsnet-onboard-cloud-detection-and-atmospheric-correction-with-efficient-deep-learning-models","title":"DTACSNet: Onboard Cloud Detection and Atmospheric Correction With Efficient Deep Learning Models","text":"<p>Cesar Aybar<sup>\u00a7</sup>, Gonzalo Mateo-Garc\u00eda<sup>\u00a7</sup>, Giacomo Acciarini<sup>\u00a7</sup>, Vit Ruzicka, Gabriele Meoni, Nicolas Longepe, Luis G\u00f3mez-Chova <sub><sup>\u00a7 development contribution</sup></sub></p> <p>10.1109/JSTARS.2024.3480520</p> <p>This repo contains an open implementation to run inference with DTACSNet models for atmospheric correction. This repo and trained models are released under a Creative Commons non-commercial licence </p> <p>Install \u2699\ufe0f: <pre><code>pip install dtacs\n</code></pre></p> <p>Run:</p> <pre><code>from dtacs.model_wrapper import ACModel\nmodel_atmospheric_correction = ACModel(model_name=\"CNN_corrector_phisat2\")\nmodel_atmospheric_correction.load_weights()\n\nac_output = model_atmospheric_correction.predict(l1c_toa_s2)\n</code></pre> <p> The figure above shows a sample of Sentinel-2 level 1C, DTACSNet model output and Sentinel-2 level 2A in the RGB (first row) and in the SWIR, NIR, Red (last row) composites.</p> <p>See the inference tutorial for a complete example.</p>"},{"location":"index.html#citation","title":"Citation","text":"<p>If you find this work useful for your research, please consider citing our work:</p> <pre><code>@article{aybar_onboard_2024,\n    title = {Onboard {Cloud} {Detection} and {Atmospheric} {Correction} {With} {Efficient} {Deep} {Learning} {Models}},\n    volume = {17},\n    issn = {2151-1535},\n    url = {https://ieeexplore.ieee.org/abstract/document/10716772},\n    doi = {10.1109/JSTARS.2024.3480520},\n    urldate = {2024-11-12},\n    journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},\n    author = {Aybar, Cesar and Mateo-Garc\u00eda, Gonzalo and Acciarini, Giacomo and R\u016f\u017ei\u010dka, V\u00edt and Meoni, Gabriele and Long\u00e9p\u00e9, Nicolas and G\u00f3mez-Chova, Luis},\n    year = {2024},\n    note = {Conference Name: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},\n    pages = {19518--19529}\n}\n</code></pre>"},{"location":"index.html#acknowledgments","title":"Acknowledgments","text":"<p>DTACSNet has been developed by Trillium Technologies. It has been funded by ESA Cognitive Cloud Computing in Space initiative project number D-TACS I-2022-00380.</p>"},{"location":"index.html#more-cloud-detection-viz","title":"More Cloud Detection Viz","text":"<p> Thick cloud  Thin cloud   Cloud shadow</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"index.html#more-atmospheric-correction-viz","title":"More Atmospheric Correction Viz","text":""},{"location":"tutorials/inference-Phi-Sat-II.html","title":"Inference Phi-Sat-II","text":"<pre><code># download the image\nimport os\nif not os.path.exists(\"examples/phisat2-l1c.tiff\"):\n    !wget -P examples/ https://cloud.sinergise.com/s/RSgHGwWWCxYp5yq/download/phisat2-l1c.tiff \n</code></pre> <pre><code>import sys\nsys.path.append(\"..\")\n</code></pre> <pre><code>import rasterio\nimport rasterio.windows\nimport os\n\n\nphisat2_bands = [\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\"]\n\nPHISAT2_PAN_BANDS = [\"B2\", \"B3\", \"B4\", \"PAN\", \"B8\", \"B5\", \"B6\", \"B7\"]\n\nfolder_examples = \"examples\"\n\nwith rasterio.open(os.path.join(folder_examples,\"phisat2-l1c.tiff\")) as rst:\n    indexes_read = [PHISAT2_PAN_BANDS.index(b) + 1 for b in phisat2_bands]\n    data = rst.read(indexes_read).astype(\"float32\") * 10_000 # Convert to the same units as S2 TOA images\n    transform_phisat2 = rst.transform\ndata.shape\n</code></pre> <pre>\n<code>(7, 4096, 4096)</code>\n</pre> <pre><code># Data are TOA reflectance values. We multiply them by 10_000 to use the same convention as in Sentinel-2\ndata\n</code></pre> <pre>\n<code>array([[[1322.5994 , 1320.0856 , 1320.9397 , ..., 1042.8582 ,\n         1037.9543 , 1032.7795 ],\n        [1317.1211 , 1313.7217 , 1314.116  , ..., 1028.6802 ,\n         1026.053  , 1023.8384 ],\n        [1315.6958 , 1308.3627 , 1306.545  , ..., 1015.23615,\n         1009.0241 , 1009.10614],\n        ...,\n        [1430.4143 , 1428.8866 , 1416.1835 , ...,  934.9696 ,\n          944.6366 ,  950.5102 ],\n        [1429.8018 , 1424.3774 , 1407.938  , ...,  930.64264,\n          938.4229 ,  944.8581 ],\n        [1426.832  , 1418.0771 , 1400.1425 , ...,  929.38654,\n          931.2642 ,  934.7899 ]],\n\n       [[1360.229  , 1338.267  , 1292.3629 , ..., 1023.04486,\n         1010.3757 , 1008.6486 ],\n        [1342.062  , 1317.6985 , 1277.8824 , ..., 1020.6479 ,\n         1010.9121 , 1009.59503],\n        [1310.8638 , 1293.7273 , 1272.6669 , ..., 1016.228  ,\n         1011.0665 , 1011.6896 ],\n        ...,\n        [1514.7881 , 1492.5245 , 1452.1195 , ...,  897.7126 ,\n          913.43396,  912.3569 ],\n        [1509.8177 , 1485.543  , 1442.6339 , ...,  883.9485 ,\n          905.8627 ,  911.69574],\n        [1509.6626 , 1485.7672 , 1442.7484 , ...,  874.86005,\n          901.2488 ,  911.895  ]],\n\n       [[1033.3932 , 1028.7035 , 1018.2965 , ..., 1227.7335 ,\n         1235.5188 , 1255.2526 ],\n        [1027.109  , 1022.1214 , 1013.8055 , ..., 1185.7994 ,\n         1200.9028 , 1223.2795 ],\n        [1011.16583, 1005.5013 , 1001.6236 , ..., 1106.2363 ,\n         1116.8206 , 1140.863  ],\n        ...,\n        [1600.7773 , 1567.0034 , 1523.0471 , ...,  699.65967,\n          693.79926,  693.8701 ],\n        [1607.5692 , 1567.5837 , 1500.4966 , ...,  686.4775 ,\n          708.05176,  718.30365],\n        [1608.4591 , 1571.6168 , 1502.3864 , ...,  668.43634,\n          709.58386,  731.99615]],\n\n       ...,\n\n       [[2865.501  , 2877.168  , 2896.6174 , ..., 2397.5806 ,\n         2408.7175 , 2411.5754 ],\n        [2910.6616 , 2917.7883 , 2925.9536 , ..., 2381.6914 ,\n         2383.2058 , 2386.7314 ],\n        [2997.9626 , 3000.0742 , 2994.6182 , ..., 2353.371  ,\n         2357.1824 , 2363.8162 ],\n        ...,\n        [2795.5955 , 2786.0886 , 2780.7942 , ..., 2003.6438 ,\n         1992.5857 , 1997.2983 ],\n        [2804.8813 , 2780.6316 , 2752.8333 , ..., 2009.3411 ,\n         2005.3824 , 2006.0068 ],\n        [2808.557  , 2778.3118 , 2741.2388 , ..., 2016.016  ,\n         2008.3715 , 2005.9791 ]],\n\n       [[3600.7786 , 3600.3042 , 3614.4646 , ..., 2733.0044 ,\n         2729.215  , 2717.5703 ],\n        [3598.449  , 3604.9832 , 3630.5503 , ..., 2722.8826 ,\n         2713.4092 , 2701.8696 ],\n        [3590.9646 , 3616.0625 , 3667.7424 , ..., 2717.4773 ,\n         2701.5737 , 2690.5364 ],\n        ...,\n        [3108.8032 , 3106.8699 , 3092.6897 , ..., 2463.1504 ,\n         2452.1025 , 2444.5637 ],\n        [3095.445  , 3088.4348 , 3079.641  , ..., 2460.2698 ,\n         2433.2341 , 2427.4868 ],\n        [3095.9392 , 3087.4583 , 3077.9648 , ..., 2463.0059 ,\n         2429.3193 , 2424.994  ]],\n\n       [[3584.3557 , 3568.8684 , 3505.664  , ..., 2548.6487 ,\n         2534.796  , 2524.942  ],\n        [3550.0635 , 3541.381  , 3492.8608 , ..., 2564.5261 ,\n         2550.476  , 2540.0837 ],\n        [3487.404  , 3492.49   , 3475.8538 , ..., 2591.5137 ,\n         2576.6697 , 2572.516  ],\n        ...,\n        [3025.2507 , 3023.0496 , 2995.3074 , ..., 2291.15   ,\n         2298.512  , 2302.8228 ],\n        [3026.4873 , 3015.5457 , 2987.4424 , ..., 2319.7998 ,\n         2353.5754 , 2362.2373 ],\n        [3017.9026 , 3004.0955 , 2981.346  , ..., 2350.9143 ,\n         2395.339  , 2406.5127 ]]], dtype=float32)</code>\n</pre> <pre><code>from dtacs.model_wrapper import ACModel\nimport torch\n\nmodel_atmospheric_correction = ACModel(model_name=\"CNN_corrector_phisat2\")\nmodel_atmospheric_correction.load_weights()\n</code></pre> <pre>\n<code>/home/gonzalo/miniconda3/envs/starcop/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</code>\n</pre> <pre><code>%%time\nac_output = model_atmospheric_correction.predict(data)\nac_output\n</code></pre> <pre>\n<code>CPU times: user 5.37 s, sys: 3.78 s, total: 9.15 s\nWall time: 2.73 s\n</code>\n</pre> <pre>\n<code>array([[[ 917,  909,  897, ...,  472,  463,  455],\n        [ 905,  897,  885, ...,  456,  450,  446],\n        [ 896,  883,  872, ...,  442,  433,  432],\n        ...,\n        [1029, 1024, 1002, ...,  330,  346,  354],\n        [1028, 1018,  991, ...,  327,  343,  353],\n        [1025, 1010,  982, ...,  327,  338,  344]],\n\n       [[1288, 1261, 1201, ...,  796,  779,  776],\n        [1262, 1232, 1181, ...,  790,  778,  775],\n        [1216, 1194, 1168, ...,  781,  773,  773],\n        ...,\n        [1457, 1429, 1377, ...,  621,  642,  642],\n        [1450, 1420, 1364, ...,  606,  636,  645],\n        [1450, 1420, 1365, ...,  597,  632,  647]],\n\n       [[ 990,  982,  966, ..., 1127, 1133, 1153],\n        [ 975,  968,  956, ..., 1082, 1096, 1120],\n        [ 945,  939,  935, ...,  998, 1007, 1033],\n        ...,\n        [1618, 1582, 1530, ...,  543,  539,  540],\n        [1625, 1582, 1505, ...,  527,  554,  567],\n        [1623, 1583, 1506, ...,  507,  555,  581]],\n\n       ...,\n\n       [[3185, 3197, 3223, ..., 2563, 2573, 2572],\n        [3231, 3240, 3255, ..., 2543, 2542, 2543],\n        [3320, 3325, 3329, ..., 2512, 2512, 2515],\n        ...,\n        [3027, 3019, 3013, ..., 2148, 2137, 2141],\n        [3034, 3010, 2984, ..., 2154, 2144, 2143],\n        [3038, 3008, 2972, ..., 2161, 2144, 2139]],\n\n       [[3825, 3825, 3845, ..., 2825, 2820, 2804],\n        [3823, 3831, 3863, ..., 2813, 2802, 2787],\n        [3818, 3845, 3904, ..., 2810, 2790, 2776],\n        ...,\n        [3257, 3258, 3245, ..., 2558, 2547, 2540],\n        [3242, 3237, 3232, ..., 2555, 2523, 2517],\n        [3242, 3235, 3229, ..., 2559, 2516, 2510]],\n\n       [[4073, 4052, 3978, ..., 2771, 2751, 2735],\n        [4021, 4011, 3958, ..., 2789, 2770, 2753],\n        [3928, 3936, 3926, ..., 2823, 2801, 2791],\n        ...,\n        [3349, 3349, 3316, ..., 2517, 2529, 2533],\n        [3346, 3338, 3310, ..., 2550, 2586, 2596],\n        [3335, 3324, 3305, ..., 2586, 2633, 2645]]], dtype=uint16)</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\nfrom dtacs import plot\nimport rasterio.plot as rstplt\n\nfig, ax = plt.subplots(2,2,figsize=(12,12),tight_layout=True)\n\nrstplt.show(data[2::-1,...]/4_000,ax=ax[0,0])\nax[0,0].set_title(\"RGB PhiSat-II L1C\")\nrstplt.show(ac_output[2::-1,...]/4_000,ax=ax[0,1])\nax[0,1].set_title(\"RGB PhiSat-II L2A (DTACSNet corrected)\")\n\nnirredgreen = [-1, 2, 1]\nrstplt.show(data[nirredgreen,...]/10_000,ax=ax[1,0])\nax[1,0].set_title(\"NIRRG PhiSat-II L1C\")\nrstplt.show(ac_output[nirredgreen,...]/10_000,ax=ax[1,1])\nax[1,1].set_title(\"NIRRG PhiSat-II L2A (DTACSNet corrected)\")\n</code></pre> <pre>\n<code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</code>\n</pre> <pre>\n<code>Text(0.5, 1.0, 'NIRRG PhiSat-II L2A (DTACSNet corrected)')</code>\n</pre> <pre><code># Load Sentinel-2 L2A \nwith rasterio.open(os.path.join(folder_examples,\"S2L2A.tif\")) as rst:\n    indexes_read = [rst.descriptions.index(b) + 1 for b in phisat2_bands]\n    data_l2a = rst.read(indexes_read)\n\n# Load Sentinel-2 L1C \nwith rasterio.open(os.path.join(folder_examples,\"S2L1C.tif\")) as rst:\n    indexes_read = [rst.descriptions.index(b) + 1 for b in phisat2_bands]\n    data_l1c = rst.read(indexes_read)\n    bounds = rst.bounds\n\nwindow_in = rasterio.windows.from_bounds(*bounds, transform=transform_phisat2)\nslice_read = (slice(None),) + window_in.toslices()\n</code></pre> <pre><code>fig, ax = plt.subplots(2,4,figsize=(24,12),tight_layout=True)\n\nrstplt.show(data[2::-1,...][slice_read]/4_000,ax=ax[0,0])\nax[0,0].set_title(\"RGB PhiSat-II L1C\")\nrstplt.show(ac_output[2::-1,...][slice_read]/4_000,ax=ax[0,1])\nax[0,1].set_title(\"RGB PhiSat-II L2A (DTACSNet corrected)\")\n\nrstplt.show(data_l1c[2::-1,...]/4_000,ax=ax[0,2])\nax[0,2].set_title(\"RGB Sentinel-2 L1C\")\nrstplt.show(data_l2a[2::-1,...]/4_000,ax=ax[0,3])\nax[0,3].set_title(\"RGB Sentinel-2 L2A\")\n\nnirredgreen = [-1, 2, 1]\nrstplt.show(data[nirredgreen,...][slice_read]/10_000,ax=ax[1,0])\nax[1,0].set_title(\"NIRRG PhiSat-II L1C\")\nrstplt.show(ac_output[nirredgreen,...][slice_read]/10_000,ax=ax[1,1])\nax[1,1].set_title(\"NIRRG PhiSat-II L2A (DTACSNet corrected)\")\n\nrstplt.show(data_l1c[nirredgreen,...]/10_000,ax=ax[1,2])\nax[1,2].set_title(\"NIRRG PhiSat-II L1C\")\nrstplt.show(data_l2a[nirredgreen,...]/10_000,ax=ax[1,3])\nax[1,3].set_title(\"NIRRG Sentinel-2 L2A\")\n</code></pre> <pre>\n<code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n</code>\n</pre> <pre>\n<code>Text(0.5, 1.0, 'NIRRG Sentinel-2 L2A')</code>\n</pre>"},{"location":"tutorials/inference-Phi-Sat-II.html#dtacsnet-onboard-cloud-detection-and-atmospheric-correction-with-end-to-end-deep-learning-emulators","title":"DTACSNet: onboard cloud detection and atmospheric correction with end-to-end deep learning emulators","text":"<p>This repo contains an open implementation to run inference with DTACSNet models for atmospheric correction and also for cloud detection. These two models are independent (you could run one or the other or both). The trained models provided here are customized to the band configuration that will be available in Phi-Sat-II (excluding PAN band). Trained models are released under a Creative Commons non-commercial licence .</p>"},{"location":"tutorials/inference-Phi-Sat-II.html#phi-sat-ii-simulated-image-run","title":"Phi-Sat-II simulated image run","text":"<p>In this notebook we run the DTACSNet model over a simulated Phi-Sat-II image. To run this tutorial we downloaded this image from here and save it in the <code>tutorials/examples</code> folder.</p>"},{"location":"tutorials/inference-Phi-Sat-II.html#load-data","title":"Load data","text":"<p>Load the simulated Phi-Sat-II image. We multiply the values by 10,000 to follow the same convention as in Sentinel-2.</p>"},{"location":"tutorials/inference-Phi-Sat-II.html#atmospheric-correction-model","title":"Atmospheric correction model","text":""},{"location":"tutorials/inference-Phi-Sat-II.html#load-model","title":"Load model","text":""},{"location":"tutorials/inference-Phi-Sat-II.html#run-inference","title":"Run inference","text":""},{"location":"tutorials/inference-Phi-Sat-II.html#plot","title":"Plot","text":""},{"location":"tutorials/inference-Phi-Sat-II.html#compare-l2a-phi-sat-ii-image-with-l2a-sentinel-2-image","title":"Compare L2A Phi-Sat-II image with L2A Sentinel-2 image","text":"<p>The simulated Phi-Sat-II image that we have shown below has been created from the Sentinel-2 tile: <code>S2A_MSIL1C_20191111T132241_N0208_R038_T23LLK_20191111T145626</code>. We have copied a 500x500 subset of this tile in the <code>tutorials/examples</code> folder. We have also downloaded the corresponding L2A Sentinel-2 file to compare the atmospheric correction output of the two products.</p>"},{"location":"tutorials/inference_Sentinel-2.html","title":"Inference Sentinel-2","text":"<pre><code># pip install dtacs\n</code></pre> <pre><code>import rasterio\nimport os\n\n\nphisat2_bands = [\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\"]\n\nfolder_examples = \"examples\"\n# In the Google Earth Engine its id is `var img = ee.Image(\"COPERNICUS/S2_HARMONIZED/20191111T132241_20191111T132235_T23LLK\");` \n\n\nwith rasterio.open(os.path.join(folder_examples,\"S2L1C.tif\")) as rst:\n    indexes_read = [rst.descriptions.index(b) + 1 for b in phisat2_bands]\n    data = rst.read(indexes_read)\ndata.shape\n</code></pre> <pre>\n<code>(7, 509, 509)</code>\n</pre> <pre><code>data\n</code></pre> <pre>\n<code>array([[[ 991.,  982.,  966., ..., 1089., 1096., 1059.],\n        [ 996.,  992.,  992., ..., 1062., 1080., 1076.],\n        [1010.,  962.,  976., ..., 1064., 1072., 1094.],\n        ...,\n        [1053., 1550., 1870., ...,  952.,  979.,  988.],\n        [1404., 2125., 2356., ...,  979.,  980., 1004.],\n        [1608., 2245., 2476., ...,  960.,  973.,  983.]],\n\n       [[ 954.,  932.,  922., ..., 1044., 1063., 1045.],\n        [ 969.,  957.,  958., ..., 1006., 1046., 1055.],\n        [ 997.,  956.,  944., ..., 1004., 1062., 1077.],\n        ...,\n        [1268., 1925., 2120., ...,  998., 1013.,  961.],\n        [1614., 2223., 2387., ..., 1001., 1001.,  975.],\n        [1667., 2116., 2384., ..., 1004., 1013., 1015.]],\n\n       [[ 791.,  785.,  692., ..., 1142., 1115., 1039.],\n        [ 817.,  802.,  768., ..., 1013., 1093., 1099.],\n        [ 856.,  745.,  750., ...,  976., 1014., 1062.],\n        ...,\n        [1605., 2188., 2344., ...,  662.,  617.,  657.],\n        [1740., 2223., 2446., ...,  649.,  627.,  650.],\n        [1571., 2046., 2487., ...,  603.,  625.,  627.]],\n\n       ...,\n\n       [[2310., 2337., 2337., ..., 2163., 2099., 2099.],\n        [2310., 2337., 2337., ..., 2163., 2099., 2099.],\n        [2318., 2387., 2387., ..., 2291., 2223., 2223.],\n        ...,\n        [2020., 3246., 3246., ..., 2773., 2788., 2788.],\n        [2020., 3246., 3246., ..., 2773., 2788., 2788.],\n        [2433., 3233., 3233., ..., 2976., 2858., 2858.]],\n\n       [[2806., 2838., 2838., ..., 2542., 2590., 2590.],\n        [2806., 2838., 2838., ..., 2542., 2590., 2590.],\n        [2741., 2987., 2987., ..., 2732., 2687., 2687.],\n        ...,\n        [2419., 3470., 3470., ..., 3398., 3337., 3337.],\n        [2419., 3470., 3470., ..., 3398., 3337., 3337.],\n        [3041., 3503., 3503., ..., 3621., 3467., 3467.]],\n\n       [[2635., 2549., 2696., ..., 2285., 2320., 2524.],\n        [2605., 2594., 2544., ..., 2283., 2406., 2445.],\n        [2630., 2827., 2712., ..., 2454., 2637., 2547.],\n        ...,\n        [1641., 2585., 2960., ..., 3219., 3330., 3077.],\n        [2197., 3122., 3377., ..., 3104., 3239., 3210.],\n        [2460., 3113., 3395., ..., 3388., 3400., 3253.]]], dtype=float32)</code>\n</pre> <pre><code>from dtacs.model_wrapper import ACModel\n\nmodel_atmospheric_correction = ACModel(model_name=\"CNN_corrector_phisat2\")\nmodel_atmospheric_correction.load_weights()\n</code></pre> <pre>\n<code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.13k/4.13k [00:00&lt;00:00, 3.09MiB/s]\n/home/gonzalo/git/DTACSNet/dtacs/model_wrapper.py:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  weights =  torch.load(fh, map_location=self.device)\n</code>\n</pre> <pre><code>ac_output = model_atmospheric_correction.predict(data)\nac_output\n</code></pre> <pre>\n<code>array([[[ 417,  396,  388, ...,  526,  537,  506],\n        [ 423,  416,  412, ...,  489,  522,  521],\n        [ 447,  390,  397, ...,  496,  530,  552],\n        ...,\n        [ 451, 1153, 1614, ...,  394,  445,  427],\n        [ 989, 1968, 2301, ...,  419,  437,  461],\n        [1237, 2103, 2449, ...,  408,  436,  436]],\n\n       [[ 710,  678,  668, ...,  825,  852,  833],\n        [ 728,  713,  710, ...,  770,  833,  846],\n        [ 762,  718,  700, ...,  772,  857,  875],\n        ...,\n        [1059, 1913, 2236, ...,  766,  794,  721],\n        [1575, 2413, 2677, ...,  768,  775,  749],\n        [1661, 2303, 2699, ...,  775,  795,  790]],\n\n       [[ 646,  629,  532, ..., 1044, 1027,  948],\n        [ 674,  651,  612, ...,  900, 1004, 1012],\n        [ 722,  592,  594, ...,  859,  918,  970],\n        ...,\n        [1530, 2249, 2493, ...,  494,  452,  483],\n        [1768, 2415, 2710, ...,  479,  458,  485],\n        [1618, 2247, 2780, ...,  424,  459,  456]],\n\n       ...,\n\n       [[2503, 2541, 2535, ..., 2323, 2266, 2254],\n        [2504, 2539, 2542, ..., 2323, 2261, 2258],\n        [2496, 2603, 2610, ..., 2477, 2393, 2398],\n        ...,\n        [2147, 3515, 3552, ..., 3036, 3044, 3056],\n        [2178, 3597, 3620, ..., 3046, 3048, 3054],\n        [2715, 3620, 3633, ..., 3273, 3131, 3138]],\n\n       [[2933, 2971, 2971, ..., 2636, 2691, 2685],\n        [2932, 2969, 2973, ..., 2642, 2688, 2686],\n        [2857, 3128, 3134, ..., 2852, 2794, 2796],\n        ...,\n        [2461, 3624, 3663, ..., 3576, 3514, 3522],\n        [2497, 3718, 3738, ..., 3586, 3516, 3522],\n        [3233, 3798, 3796, ..., 3826, 3655, 3661]],\n\n       [[2912, 2811, 2980, ..., 2505, 2569, 2799],\n        [2877, 2865, 2807, ..., 2499, 2666, 2710],\n        [2892, 3144, 3013, ..., 2700, 2921, 2820],\n        ...,\n        [1732, 2764, 3277, ..., 3569, 3694, 3403],\n        [2457, 3532, 3882, ..., 3442, 3588, 3562],\n        [2811, 3569, 3941, ..., 3757, 3778, 3608]]], dtype=uint16)</code>\n</pre> <pre><code>import matplotlib.pyplot as plt\nfrom dtacs import plot\nimport rasterio.plot as rstplt\n\n# Load L2A to show\nwith rasterio.open(os.path.join(folder_examples,\"S2L2A.tif\")) as rst:\n    indexes_read = [rst.descriptions.index(b) + 1 for b in phisat2_bands]\n    data_sen2cor = rst.read(indexes_read)\n\nfig, ax = plt.subplots(2,3,figsize=(18,12),tight_layout=True)\n\nrstplt.show(data[2::-1,...]/4_000,ax=ax[0,0])\nax[0,0].set_title(\"RGB L1C\")\nrstplt.show(ac_output[2::-1,...]/4_000,ax=ax[0,1])\nax[0,1].set_title(\"RGB DTACSNet\")\nrstplt.show(data_sen2cor[2::-1,...]/4_000,ax=ax[0,2])\nax[0,2].set_title(\"RGB L2A\")\n\nnirredgreen = [-1, 2, 1]\nrstplt.show(data[nirredgreen,...]/10_000,ax=ax[1,0])\nax[1,0].set_title(\"NIRRG L1C\")\nrstplt.show(ac_output[nirredgreen,...]/10_000,ax=ax[1,1])\nax[1,1].set_title(\"NIRRG DTACSNet\")\nrstplt.show(data_sen2cor[nirredgreen,...]/10_000,ax=ax[1,2])\nax[1,2].set_title(\"NIRRG L2A\")\n</code></pre> <pre>\n<code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.08225..1.67075].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..2.004].\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00025..2.44].\n</code>\n</pre> <pre>\n<code>Text(0.5, 1.0, 'NIRRG L2A')</code>\n</pre> <pre><code>from dtacs.model_wrapper import CDModel, DIR_MODELS_LOCAL\nimport torch\nfrom dtacs.download_weights import download_weights\nimport os\n\nassert torch.__version__ &amp;gt;= \"1.13\", f\"Requires torch version &amp;gt;=1.13 current version {torch.__version__ }\"\n\n# https://huggingface.co/isp-uv-es/cloudsen12_models/resolve/main/dtacs4bands.pt\nweights_path = os.path.join(DIR_MODELS_LOCAL,\"cloud4bands.pt\")\ndownload_weights(weights_path, \"https://huggingface.co/isp-uv-es/cloudsen12_models/resolve/main/dtacs4bands.pt\")\nmodel_cd_torchscript = torch.jit.load(weights_path, map_location='cpu')\nmodel_cloud_detection = CDModel(model=model_cd_torchscript)\n</code></pre> <pre>\n<code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41.3M/41.3M [00:01&lt;00:00, 40.9MiB/s]\n</code>\n</pre> <pre><code>data_cloud_detection = data[[-1,2,1,0],...]\n\ncd_output = model_cloud_detection.predict(data_cloud_detection)\ncd_output\n</code></pre> <pre>\n<code>array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [0, 1, 1, ..., 0, 0, 0],\n       [0, 1, 1, ..., 0, 0, 0]], dtype=uint8)</code>\n</pre> <pre><code>fig, ax = plt.subplots(1,2,figsize=(12,6),tight_layout=True)\n\nnirredgreen = [-1, 2, 1]\n\nrstplt.show(data[2::-1,...]/4_000,ax=ax[0])\nax[0].set_title(\"RGB L1C\")\n\nplot.plot_cloudSEN12mask(cd_output,ax=ax[1])\nax[1].set_title(\"Cloud shadow mask\")\n</code></pre> <pre>\n<code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.08225..1.67075].\n</code>\n</pre> <pre>\n<code>Text(0.5, 1.0, 'Cloud shadow mask')</code>\n</pre>"},{"location":"tutorials/inference_Sentinel-2.html#dtacsnet-onboard-cloud-detection-and-atmospheric-correction-with-end-to-end-deep-learning-emulators","title":"DTACSNet: onboard cloud detection and atmospheric correction with end-to-end deep learning emulators","text":"<p>This repo contains an open implementation to run inference with DTACSNet models for atmospheric correction and also for cloud detection. These two models are independent (you could run one or the other or both). The trained models provided here are customized to the band configuration that will be available in Phi-Sat-II. Trained models are released under a Creative Commons non-commercial licence .</p>"},{"location":"tutorials/inference_Sentinel-2.html#load-data","title":"Load data","text":"<p>The image that we will use for this tutorial is in the <code>tutorials/examples</code> folder. It is a small patch of this Sentinel-2 tile: <code>S2A_MSIL1C_20191111T132241_N0208_R038_T23LLK_20191111T145626</code>. The image has been been taken from CloudSEN12 dataset. It corresponds to ROI <code>ROI_0312</code> in CloudSEN12.</p>"},{"location":"tutorials/inference_Sentinel-2.html#atmospheric-correction-model","title":"Atmospheric correction model","text":""},{"location":"tutorials/inference_Sentinel-2.html#load-model","title":"Load model","text":""},{"location":"tutorials/inference_Sentinel-2.html#run-inference","title":"Run inference","text":""},{"location":"tutorials/inference_Sentinel-2.html#plot","title":"Plot","text":""},{"location":"tutorials/inference_Sentinel-2.html#cloud-detection-model","title":"Cloud detection model","text":"<p>The cloud detection model of DTACS are based on CloudSEN12 dataset. For more and better models use <code>cloudsen12_models</code>.</p>"},{"location":"tutorials/inference_Sentinel-2.html#load-model_1","title":"Load model","text":""},{"location":"tutorials/inference_Sentinel-2.html#run-inference_1","title":"Run inference","text":""}]}